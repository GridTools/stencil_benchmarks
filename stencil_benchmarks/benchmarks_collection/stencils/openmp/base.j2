#include <algorithm>
#include <chrono>
#include <cmath>
#include <cstdint>
#include <iostream>

#include <errno.h>
#include <omp.h>

{% if numa %}
#include <linux/mempolicy.h>
#include <numa.h>
#include <numaif.h>
#include <sched.h>
#include <unistd.h>

void move_to_local_numa_domain(void* begin, void* end) {
    std::size_t page_size = getpagesize();

    begin = (void*) ((std::size_t) begin / page_size * page_size);
    end = (void*) ((std::size_t) end / page_size * page_size);
    std::size_t size = (char*) end - (char*) begin;
    if (!size)
        return;

    auto local_node = numa_node_of_cpu(sched_getcpu());
    auto* bitmask = numa_allocate_nodemask();
    numa_bitmask_clearall(bitmask);
    numa_bitmask_setbit(bitmask, local_node);
    if (mbind(begin, size, MPOL_BIND, bitmask->maskp, bitmask->size, MPOL_MF_MOVE | MPOL_MF_STRICT)) {
        auto errsv = errno;
        std::cerr << "mbind failed on OpenMP thread " << omp_get_thread_num()
                  << " (CPU " << sched_getcpu() << ") with error " << strerror(errsv);
    }
    numa_free_nodemask(bitmask);
}
{% endif %}

{%- if ctype == 'float' %}
using index_t = std::int32_t;
{%- elif ctype == 'double' %}
using index_t = std::int64_t;
{%- endif %}

{%- if vector_size is defined %}
  using unaligned_vec_t = {{ ctype }} __attribute__((vector_size({{ vector_size }} * sizeof({{ ctype }})), aligned(sizeof({{ ctype }}))));
  using ivec_t = index_t __attribute__((vector_size({{ vector_size }} * sizeof(index_t))));
  {%- if ctype == 'float' %}
    {%- if alignment is defined and alignment > 0 and alignment % (4 * vector_size) == 0 %}
      using vec_t = {{ ctype }} __attribute__((vector_size({{ vector_size }} * sizeof({{ ctype }}))));

      {%- if streaming_stores %}
      #if defined(__SSE__) && {{ vector_size }} == 4
      #define NTSTORE(ptr, val) __builtin_ia32_movntps((ptr), (val))
      #elif defined(__AVX__) && {{ vector_size }} == 8
      #define NTSTORE(ptr, val) __builtin_ia32_movntps256((ptr), (val))
      #elif defined(__AVX512F__) && {{ vector_size }} == 16
      #define NTSTORE(ptr, val) __builtin_ia32_movntps512((ptr), (val))
      #else
      #define NTSTORE(ptr, val) *(vec_t*)(ptr) = val
      #endif
      {%- else %}
      #define NTSTORE(ptr, val) *(vec_t*)(ptr) = val
      {% endif %}
    {%- else %}
      using vec_t = unaligned_vec_t;
      #define NTSTORE(ptr, val) *(vec_t*)(ptr) = val
    {%- endif %}
  {%- elif ctype == 'double' %}
    {%- if alignment is defined and alignment > 0 and alignment % (8 * vector_size) == 0 %}
      using vec_t = {{ ctype }} __attribute__((vector_size({{ vector_size }} * sizeof({{ ctype }}))));

      {%- if streaming_stores %}
      #if defined(__SSE__) && {{ vector_size }} == 2
      #define NTSTORE(ptr, val) __builtin_ia32_movntpd((ptr), (val))
      #elif defined(__AVX__) && {{ vector_size }} == 4
      #define NTSTORE(ptr, val) __builtin_ia32_movntpd256((ptr), (val))
      #elif defined(__AVX512F__) && {{ vector_size }} == 8
      #define NTSTORE(ptr, val) __builtin_ia32_movntpd512((ptr), (val))
      #else
      #define NTSTORE(ptr, val) *(vec_t*)(ptr) = val
      #endif
      {%- else %}
      #define NTSTORE(ptr, val) *(vec_t*)(ptr) = val
      {% endif %}
    {%- else %}
      using vec_t = unaligned_vec_t;
      #define NTSTORE(ptr, val) *(vec_t*)(ptr) = val
    {%- endif %}
  {%- endif %}

{%- endif %}

{% block pre_kernel %}
{% endblock pre_kernel %}

{% block kernel %}
extern "C" int kernel(
    double* time,
    {%- for arg in args %}
        {{ ctype }} * __restrict__ {{ arg }}{{ "," if not loop.last }}
    {%- endfor %}
) {
    {% block kernel_prepare %}
    {% endblock kernel_prepare %}

    using clock = std::chrono::high_resolution_clock;
    auto start = clock::now();

    {% block kernel_invoke %}
    {% endblock kernel_invoke %}

    auto stop = clock::now();
    *time = std::chrono::duration<double>(stop - start).count();
    return 0;
}
{% endblock kernel %}
